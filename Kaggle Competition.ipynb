{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "     return gini(a, p) / gini(a, a)\n",
    "    \n",
    "def gini_score(estimator, train, target):\n",
    "    prediction = estimator.predict_proba(train)\n",
    "    return gini(target, prediction[:, 1]) / gini(target, target)\n",
    "\n",
    "def test_gini():\n",
    "    def fequ(a,b):\n",
    "        return abs( a -b) < 1e-6\n",
    "    def T(a, p, g, n):\n",
    "        assert( fequ(gini(a,p), g) )\n",
    "        assert( fequ(gini_normalized(a,p), n) )\n",
    "        T([1, 2, 3], [10, 20, 30], 0.111111, 1)\n",
    "        T([1, 2, 3], [30, 20, 10], -0.111111, -1)\n",
    "        T([1, 2, 3], [0, 0, 0], -0.111111, -1)\n",
    "        T([3, 2, 1], [0, 0, 0], 0.111111, 1)\n",
    "        T([1, 2, 4, 3], [0, 0, 0, 0], -0.1, -0.8)\n",
    "        T([2, 1, 4, 3], [0, 0, 2, 1], 0.125, 1)\n",
    "        T([0, 20, 40, 0, 10], [40, 40, 10, 5, 5], 0, 0)\n",
    "        T([40, 0, 20, 0, 10], [1000000, 40, 40, 5, 5], 0.171428,\n",
    "           0.6)\n",
    "        T([40, 20, 10, 0, 0], [40, 20, 10, 0, 0], 0.285714, 1)\n",
    "        T([1, 1, 0, 1], [0.86, 0.26, 0.52, 0.32], -0.041666,\n",
    "           -0.333333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTarget(dataFrame):\n",
    "    arr = np.array(dataFrame, dtype=np.float)\n",
    "    Ytarget = dataFrame[\"target\"].values\n",
    "    return Ytarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTrain(dataFrame):\n",
    "    data = dataFrame.values\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(train, target, folds):\n",
    "    model = LogisticRegression()\n",
    "    predictions = cross_val_predict(model, train, target, cv = folds, method = 'predict_proba')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticPredict(train, target, test):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(train, target)\n",
    "    predictions = model.predict_proba(test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboostPredict(train, target, test):\n",
    "    model = XGBClassifier(max_depth=8, )\n",
    "    model.fit(train, target)\n",
    "    predictions = model.predict_proba(test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboostGridSearch(train, target):\n",
    "    xgb_model = XGBClassifier()\n",
    "    parameters = {\n",
    "        #'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "        #'objective':['binary:logistic'],\n",
    "        #'learning_rate': [0.05], #so called `eta` value\n",
    "        'max_depth': [1, 2]\n",
    "        #'min_child_weight': [11],\n",
    "        #'silent': [1],\n",
    "        #'subsample': [0.5, 0.8],\n",
    "        #'colsample_bytree': [0.5, 0.7],\n",
    "        #'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "        #'missing':[-999],\n",
    "        #'seed': [1337]\n",
    "    }\n",
    "    \n",
    "    clf = GridSearchCV(xgb_model, parameters, n_jobs=5, cv=3,\n",
    "                       scoring=gini_score,\n",
    "                       verbose=2, refit=True)\n",
    "    clf.fit(train, target)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catBinExtractor(headers):\n",
    "    catBinHeaders = []\n",
    "    for header in headers:\n",
    "        if header.endswith(\"_cat\") or header.endswith(\"_bin\"):\n",
    "            catBinHeaders.append(header)\n",
    "    return catBinHeaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingValCounter(df):\n",
    "    count = (df == -1).astype(int).sum(axis=0)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumNans(row):\n",
    "    unique, counts = np.unique(row, return_counts=True)\n",
    "    nums = dict(zip(unique, counts))\n",
    "    try:\n",
    "        if nums[-1] > 0:\n",
    "            row[\"new_column\" + nums[-1]] = 1\n",
    "    except:\n",
    "        pass\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(array):\n",
    "    imp = Imputer(missing_values=-1, strategy='mean', axis=0)\n",
    "    newArray = imp.fit_transform(array)\n",
    "    return newArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPca(array):\n",
    "    pca = PCA(n_components=array.shape[1])\n",
    "    return pca.fit(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataNormalizer(array):\n",
    "    normalizer = Normalizer(norm='max')\n",
    "    normArray = normalizer.fit_transform(array)\n",
    "    return normArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(ids, predictions):\n",
    "    with open('submission.csv', 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(['id', 'target'])\n",
    "        zipped = zip(ids, predictions[:, 1])\n",
    "        for id_, prediction in zipped:\n",
    "            writer.writerow([id_, prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFrame = loadData(\"data/train.csv\")\n",
    "testData = loadData(\"data/test.csv\")\n",
    "Ytarget = extractTarget(dataFrame)\n",
    "headers = dataFrame.columns\n",
    "testHeaders = dataFrame.columns\n",
    "catBinHeaders = catBinExtractor(headers)\n",
    "catTestHeaders = catBinExtractor(testHeaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCatBin = dataFrame[catBinHeaders]\n",
    "dfCatBin = dfCatBin + 1\n",
    "dataFrame = dataFrame.drop(catBinHeaders, axis = 1)\n",
    "\n",
    "dfTestCat = testData[catTestHeaders]\n",
    "dfTestCat = dfTestCat + 1\n",
    "testData = testData.drop(catTestHeaders, axis = 1)\n",
    "del testData[\"id\"]\n",
    "\n",
    "Xtest = extractTrain(testData)\n",
    "encTest = OneHotEncoder()\n",
    "encTest.fit(dfTestCat)\n",
    "onehottest = encTest.transform(dfTestCat).toarray()\n",
    "\n",
    "del dataFrame[\"target\"]\n",
    "del dataFrame[\"id\"]\n",
    "Xtrain = extractTrain(dataFrame)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(dfCatBin)\n",
    "onehotlabels = enc.transform(dfCatBin).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.concatenate((Xtrain, onehotlabels), axis = 1)\n",
    "Xtest = np.concatenate((Xtest, onehottest), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca1 = runPca(Xtrain)\n",
    "#print(pca1.explained_variance_ratio_)\n",
    "#print(pca1.singular_values_)\n",
    "Xtrain = imputer(Xtrain)\n",
    "Xtest = imputer(Xtest)\n",
    "#pca2 = runPca(Xtrain)\n",
    "#print(pca2.explained_variance_ratio_)\n",
    "#for eigenval in pca1.explained_variance_ratio_:\n",
    "#    if eigenval < 1e-34:\n",
    "#        print(eigenval)\n",
    "Xtrain = dataNormalizer(Xtrain)\n",
    "Xtest = dataNormalizer(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsLR = logisticRegression(Xtrain, Ytarget, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsXG = xgboostPredict(Xtrain, Ytarget, Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] max_depth=1 .....................................................\n",
      "[CV] max_depth=1 .....................................................\n",
      "[CV] max_depth=1 .....................................................\n",
      "[CV] max_depth=2 .....................................................\n",
      "[CV] max_depth=2 .....................................................\n",
      "[CV] ............................................ max_depth=1 -  27.0s\n",
      "[CV] max_depth=2 .....................................................\n",
      "[CV] ............................................ max_depth=1 -  29.5s\n",
      "[CV] ............................................ max_depth=1 -  30.0s\n",
      "[CV] ............................................ max_depth=2 -  35.2s\n",
      "[CV] ............................................ max_depth=2 -  41.6s\n",
      "[CV] ............................................ max_depth=2 -  15.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   6 out of   6 | elapsed:   42.8s finished\n"
     ]
    }
   ],
   "source": [
    "#gini_normalized(Ytarget, predictionsLR[:, 1])\n",
    "predictionsGrid = xgboostGridSearch(shortTrain, shortTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gini_normalized(Ytarget, predictionsXG[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = loadData(\"data/test.csv\")\n",
    "ids = ids[\"id\"]\n",
    "generate_submission(ids, predictionsXG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
