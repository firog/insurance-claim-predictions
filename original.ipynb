{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingValCounter(df):\n",
    "    count = (df == -1).astype(int).sum(axis=1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n"
     ]
    }
   ],
   "source": [
    "print('loading files...')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "col_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "low_variance_col = [\"ps_ind_11_bin\", \"ps_ind_13_bin\", \"ps_ind_12_bin\", \"ps_ind_18_bin\", \"ps_car_10_cat\", \n",
    "                    \"ps_car_11_cat\"]\n",
    "train = train.drop(col_to_drop, axis=1)\n",
    "test = test.drop(col_to_drop, axis=1)\n",
    "missValsTrain = missingValCounter(train)\n",
    "missValsTest = missingValCounter(test)\n",
    "\n",
    "train[\"ps_car_12\"] = train[\"ps_car_12\"].apply(lambda x: round(x**2, 4) * 10000)\n",
    "train[\"ps_car_13\"] = train[\"ps_car_13\"].apply(lambda x: round(x**2 * 48400, 2))\n",
    "train[\"ps_car_15\"] = train[\"ps_car_15\"].apply(lambda x: round(x**2))\n",
    "\n",
    "test[\"ps_car_12\"] = test[\"ps_car_12\"].apply(lambda x: round(x**2, 4) * 10000)\n",
    "test[\"ps_car_13\"] = test[\"ps_car_13\"].apply(lambda x: round(x**2 * 48400, 2))\n",
    "test[\"ps_car_15\"] = test[\"ps_car_15\"].apply(lambda x: round(x**2))\n",
    "\n",
    "missValsTrain = missValsTrain.to_frame(\"missingVals\")\n",
    "missValsTest = missValsTest.to_frame(\"missingVals\")\n",
    "\n",
    "train[\"missing_values\"] = missValsTrain[\"missingVals\"].values\n",
    "test[\"missing_values\"] = missValsTest[\"missingVals\"].values\n",
    "\n",
    "#train = train.drop(low_variance_col, axis=1)\n",
    "#test = test.drop(low_variance_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = train.columns[train.columns.str.endswith(\"_cat\")]\n",
    "cat_col_val = train[cat_cols]\n",
    "cat_col_val = cat_col_val + 1\n",
    "\n",
    "cat_col_test = test.columns[test.columns.str.endswith(\"_cat\")] \n",
    "cat_col_val_test = test[cat_col_test]\n",
    "cat_col_val_test = cat_col_val_test + 1\n",
    "\n",
    "encTrain = OneHotEncoder()\n",
    "#train.drop(cat_cols)\n",
    "encTrain.fit(cat_col_val)\n",
    "oneHotVal = encTrain.transform(cat_col_val).toarray()\n",
    "\n",
    "encTest = OneHotEncoder()\n",
    "#test.drop(cat_col_test)\n",
    "encTest.fit(cat_col_val_test)\n",
    "oneHotValTest = encTest.transform(cat_col_val_test).toarray()\n",
    "\n",
    "test = test.drop(cat_col_test, axis=1)\n",
    "train = train.drop(cat_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_train = pd.DataFrame(oneHotVal)\n",
    "new_features_train.rename(columns=lambda x: x+1, inplace=True)\n",
    "new_features_train.rename(columns=lambda x: \"feature_\" + str(x), inplace=True)\n",
    "train = pd.concat([train, new_features_train], axis=1)\n",
    "\n",
    "new_features_test = pd.DataFrame(oneHotValTest)\n",
    "new_features_test.rename(columns=lambda x: x+1, inplace=True)\n",
    "new_features_test.rename(columns=lambda x: \"feature_\" + str(x), inplace=True)\n",
    "test = pd.concat([test, new_features_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [i for i in range(1,len(new_features_train.columns))]\n",
    "for i in lst:\n",
    "    new_features_train[str(i)] = new_features_train[\"feature_\" + str(i)].apply(lambda x: int(x))\n",
    "for i in lst:\n",
    "    new_features_test[str(i)] = new_features_test[\"feature_\" + str(i)].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all zeros\n",
    "del train[\"feature_77\"]\n",
    "del test[\"feature_77\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 209) (892816, 208)\n"
     ]
    }
   ],
   "source": [
    "for c in train.select_dtypes(include=['float64']).columns:\n",
    "    train[c]=train[c].astype(np.float32)\n",
    "    test[c]=test[c].astype(np.float32)\n",
    "for c in train.select_dtypes(include=['int64']).columns[2:]:\n",
    "    train[c]=train[c].astype(np.int8)\n",
    "    test[c]=test[c].astype(np.int8)    \n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "\n",
    "def gini_xgb(pred, y):\n",
    "    y = y.get_label()\n",
    "    return 'gini', gini(y, pred) / gini(y, y)\n",
    "\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = gini(y, preds) / gini(y, y)\n",
    "    return 'gini', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['id', 'target'], axis=1)\n",
    "features = X.columns\n",
    "X = X.values\n",
    "y = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " xgb kfold: 1  of  5 : \n",
      "[0]\ttrain-gini:0.214602\tvalid-gini:0.214817\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.260011\tvalid-gini:0.245799\n",
      "[200]\ttrain-gini:0.268219\tvalid-gini:0.250739\n",
      "[300]\ttrain-gini:0.281584\tvalid-gini:0.257408\n",
      "[400]\ttrain-gini:0.299368\tvalid-gini:0.265813\n",
      "[500]\ttrain-gini:0.313437\tvalid-gini:0.271484\n",
      "[600]\ttrain-gini:0.324525\tvalid-gini:0.275315\n",
      "[700]\ttrain-gini:0.334755\tvalid-gini:0.278077\n",
      "[800]\ttrain-gini:0.343734\tvalid-gini:0.279764\n",
      "[900]\ttrain-gini:0.351245\tvalid-gini:0.28115\n",
      "[1000]\ttrain-gini:0.358376\tvalid-gini:0.281923\n",
      "[1100]\ttrain-gini:0.365166\tvalid-gini:0.282593\n",
      "[1200]\ttrain-gini:0.371502\tvalid-gini:0.282927\n",
      "[1300]\ttrain-gini:0.377746\tvalid-gini:0.283198\n",
      "[1400]\ttrain-gini:0.383625\tvalid-gini:0.283351\n",
      "[1500]\ttrain-gini:0.388977\tvalid-gini:0.283589\n"
     ]
    }
   ],
   "source": [
    "# xgb\n",
    "params = {'eta': 0.01, 'max_depth': 5, 'subsample': 0.8, 'colsample_bytree': 0.9, \n",
    "          'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': True}\n",
    "\n",
    "\n",
    "sub=test['id'].to_frame()\n",
    "sub['target']=0\n",
    "\n",
    "nrounds=2000\n",
    "kfold = 5\n",
    "\n",
    "#skf = StratifiedKFold(n_splits=kfold, random_state=1)\n",
    "#for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "#    print(' log kfold: {}  of {} : '.format(i+1, kfold))\n",
    "#    X_train, X_valid = X[train_index], X[test_index]\n",
    "#    y_train, y_valid = y[train_index], y[test_index]\n",
    "#    log_model = LogisticRegression()\n",
    "#    predictions = log_model.train()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=1)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    d_train = xgb.DMatrix(X_train, y_train) \n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid) \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100, \n",
    "                          feval=gini_xgb, maximize=True, verbose_eval=100)\n",
    "    \n",
    "    sub['target'] += xgb_model.predict(xgb.DMatrix(test[features].values), \n",
    "                        ntree_limit=xgb_model.best_ntree_limit+50) / (2*kfold)\n",
    "gc.collect()\n",
    "\n",
    "# lgb\n",
    "params = {'metric': 'auc', 'learning_rate' : 0.1, 'max_depth':10, 'max_bin':10,  'objective': 'binary', \n",
    "          'feature_fraction': 0.8,'bagging_fraction':0.9,'bagging_freq':10,  'min_data': 500}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=1)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(' lgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_eval = X[train_index], X[test_index]\n",
    "    y_train, y_eval = y[train_index], y[test_index]\n",
    "    lgb_model = lgb.train(params, lgb.Dataset(X_train, label=y_train), nrounds, \n",
    "                  lgb.Dataset(X_eval, label=y_eval), verbose_eval=100, \n",
    "                  feval=gini_lgb, early_stopping_rounds=100)\n",
    "    \n",
    "    sub['target'] += lgb_model.predict(test[features].values, \n",
    "                        num_iteration=lgb_model.best_iteration) / (2*kfold)\n",
    "\n",
    "skf = StratifiedK\n",
    "sub.to_csv('sub10.csv', index=False, float_format='%.5f') \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.278454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-62ab42495b2c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-62ab42495b2c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    xgb kfold: 1  of  5 :\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " xgb kfold: 1  of  5 : \n",
    "[0]\ttrain-gini:0.199908\tvalid-gini:0.194267\n",
    "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
    "\n",
    "Will train until valid-gini hasn't improved in 100 rounds.\n",
    "[100]\ttrain-gini:0.260527\tvalid-gini:0.250359\n",
    "[200]\ttrain-gini:0.269496\tvalid-gini:0.253377\n",
    "[300]\ttrain-gini:0.282427\tvalid-gini:0.258978\n",
    "[400]\ttrain-gini:0.297443\tvalid-gini:0.266783\n",
    "[500]\ttrain-gini:0.310735\tvalid-gini:0.271728\n",
    "[600]\ttrain-gini:0.321808\tvalid-gini:0.275316\n",
    "[700]\ttrain-gini:0.331675\tvalid-gini:0.278089\n",
    "[800]\ttrain-gini:0.340027\tvalid-gini:0.279733\n",
    "[900]\ttrain-gini:0.347624\tvalid-gini:0.281073\n",
    "[1000]\ttrain-gini:0.354826\tvalid-gini:0.281934\n",
    "[1100]\ttrain-gini:0.361346\tvalid-gini:0.282563\n",
    "[1200]\ttrain-gini:0.367924\tvalid-gini:0.282746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
